{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Libraries\n",
    "# Standard library\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nnet import conv\n",
    "from theano.tensor.nnet import softmax\n",
    "from theano.tensor import shared_randomstreams\n",
    "from theano.tensor.signal import downsample\n",
    "from theano.tensor.nnet import sigmoid\n",
    "from theano.tensor import tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to run under a GPU.  If this is not desired, then modify network3.py\n",
      "to set the GPU flag to False.\n"
     ]
    }
   ],
   "source": [
    "# 添加ReLu激活函数\n",
    "def linear(z): return z\n",
    "def ReLU(z): return T.maximum(0.0, z)\n",
    "\n",
    "#使用GPU进行计算\n",
    "GPU = True\n",
    "if GPU:\n",
    "    print (\"Trying to run under a GPU.  If this is not desired, then modify \"+\\\n",
    "        \"network3.py\\nto set the GPU flag to False.\")\n",
    "    try: theano.config.device = 'gpu'\n",
    "    except: pass # it's already set\n",
    "    theano.config.floatX = 'float32'\n",
    "else:\n",
    "    print (\"Running with a CPU.  If this is not desired, then the modify \"+\\\n",
    "        \"network3.py to set\\nthe GPU flag to True.\")\n",
    "\n",
    "#加载mnist数据集\n",
    "#划分为训练集 交叉验证集 测试集\n",
    "def load_data_shared(filename=\"G:/data/mnist.pkl.gz\"):\n",
    "    f = gzip.open(filename, 'rb')\n",
    "    training_data,validation_data,test_data=pickle.load(f,encoding='bytes')\n",
    "    f.close()\n",
    "    def shared(data):\n",
    "        \"\"\"Place the data into shared variables.  This allows Theano to copy\n",
    "        the data to the GPU, if one is available.\n",
    "        \"\"\"\n",
    "        shared_x = theano.shared(\n",
    "            np.asarray(data[0], dtype=theano.config.floatX), borrow=True)\n",
    "        shared_y = theano.shared(\n",
    "            np.asarray(data[1], dtype=theano.config.floatX), borrow=True)\n",
    "        return shared_x, T.cast(shared_y, \"int32\")\n",
    "    return [shared(training_data), shared(validation_data), shared(test_data)]\n",
    "\n",
    "#主网络\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, layers, mini_batch_size):\n",
    "\n",
    "        self.layers = layers\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.params = [param for layer in self.layers for param in layer.params]\n",
    "        self.x = T.matrix(\"x\")\n",
    "        self.y = T.ivector(\"y\")\n",
    "        init_layer = self.layers[0]\n",
    "        init_layer.set_inpt(self.x, self.x, self.mini_batch_size)\n",
    "        for j in range(1, len(self.layers)):\n",
    "            prev_layer, layer  = self.layers[j-1], self.layers[j]\n",
    "            layer.set_inpt(\n",
    "                prev_layer.output, prev_layer.output_dropout, self.mini_batch_size)\n",
    "        #最后一层的输出为输出\n",
    "        self.output = self.layers[-1].output\n",
    "        self.output_dropout = self.layers[-1].output_dropout\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            validation_data, test_data, lmbda=0.0):\n",
    "        #使用批量随机梯度下降\n",
    "        training_x, training_y = training_data\n",
    "        validation_x, validation_y = validation_data\n",
    "        test_x, test_y = test_data\n",
    "\n",
    "        # 训练 交叉验证 测试的批次数\n",
    "        num_training_batches = size(training_data)//mini_batch_size\n",
    "        num_validation_batches = size(validation_data)//mini_batch_size\n",
    "        num_test_batches = size(test_data)//mini_batch_size\n",
    "\n",
    "        # 定义代价函数（最小二乘法） 计算梯度 以及更新参数\n",
    "        l2_norm_squared = sum([(layer.w**2).sum() for layer in self.layers])\n",
    "        cost = self.layers[-1].cost(self)+\\\n",
    "               0.5*lmbda*l2_norm_squared/num_training_batches\n",
    "        grads = T.grad(cost, self.params)\n",
    "        updates = [(param, param-eta*grad)\n",
    "                   for param, grad in zip(self.params, grads)]\n",
    "\n",
    "        #定义函数来训练一个mini-batch，然后计算交叉验证集和测试集的准确度\n",
    "        i = T.lscalar() # mini-batch的索引\n",
    "        train_mb = theano.function(\n",
    "            [i], cost, updates=updates,\n",
    "            givens={\n",
    "                self.x:\n",
    "                training_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size],\n",
    "                self.y:\n",
    "                training_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        validate_mb_accuracy = theano.function(\n",
    "            [i], self.layers[-1].accuracy(self.y),\n",
    "            givens={\n",
    "                self.x:\n",
    "                validation_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size],\n",
    "                self.y:\n",
    "                validation_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        test_mb_accuracy = theano.function(\n",
    "            [i], self.layers[-1].accuracy(self.y),\n",
    "            givens={\n",
    "                self.x:\n",
    "                test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size],\n",
    "                self.y:\n",
    "                test_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        self.test_mb_predictions = theano.function(\n",
    "            [i], self.layers[-1].y_out,\n",
    "            givens={\n",
    "                self.x:\n",
    "                test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        # 训练\n",
    "        best_validation_accuracy = 0.0\n",
    "        for epoch in range(epochs):\n",
    "            for minibatch_index in range(num_training_batches):\n",
    "                iteration = num_training_batches*epoch+minibatch_index\n",
    "                #每训练一千个mini-batch输出一次\n",
    "                if iteration % 1000 == 0:\n",
    "                    print(\"Training mini-batch number {0}\".format(iteration))\n",
    "                cost_ij = train_mb(minibatch_index)\n",
    "                #每训练完一个epoch输出一次交叉验证集的准确度\n",
    "                if (iteration+1) % num_training_batches == 0:\n",
    "                    validation_accuracy = np.mean(\n",
    "                        [validate_mb_accuracy(j) for j in range(num_validation_batches)])\n",
    "                    print(\"Epoch {0}: validation accuracy {1:.2%}\".format(\n",
    "                        epoch, validation_accuracy))\n",
    "                    #判断是否是当前最高的准确度\n",
    "                    if validation_accuracy >= best_validation_accuracy:\n",
    "                        print(\"This is the best validation accuracy to date.\")\n",
    "                        best_validation_accuracy = validation_accuracy\n",
    "                        best_iteration = iteration\n",
    "                        #如果是则输出相应的测试集的准确度\n",
    "                        if test_data:\n",
    "                            test_accuracy = np.mean(\n",
    "                                [test_mb_accuracy(j) for j in range(num_test_batches)])\n",
    "                            print('The corresponding test accuracy is {0:.2%}'.format(\n",
    "                                test_accuracy))\n",
    "        #训练完成输出最好的交叉验证集准确度 以及相应的测试集准确度\n",
    "        print(\"Finished training network.\")\n",
    "        print(\"Best validation accuracy of {0:.2%} obtained at iteration {1}\".format(\n",
    "            best_validation_accuracy, best_iteration))\n",
    "        print(\"Corresponding test accuracy of {0:.2%}\".format(test_accuracy))\n",
    "\n",
    "#其他种类的层\n",
    "class ConvPoolLayer(object):\n",
    "    #卷积和池化层写在一起的层\n",
    "\n",
    "    def __init__(self, filter_shape, image_shape, poolsize=(2, 2),\n",
    "                 activation_fn=sigmoid):\n",
    "\n",
    "        self.filter_shape = filter_shape\n",
    "        self.image_shape = image_shape\n",
    "        self.poolsize = poolsize\n",
    "        self.activation_fn=activation_fn\n",
    "        # 初始化权值和偏置\n",
    "        n_out = (filter_shape[0]*np.prod(filter_shape[2:])/np.prod(poolsize))\n",
    "        self.w = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(loc=0, scale=np.sqrt(1.0/n_out), size=filter_shape),\n",
    "                dtype=theano.config.floatX),\n",
    "            borrow=True)\n",
    "        self.b = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(loc=0, scale=1.0, size=(filter_shape[0],)),\n",
    "                dtype=theano.config.floatX),\n",
    "            borrow=True)\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def set_inpt(self, inpt, inpt_dropout, mini_batch_size):\n",
    "        self.inpt = inpt.reshape(self.image_shape)\n",
    "        conv_out = conv.conv2d(\n",
    "            input=self.inpt, filters=self.w, filter_shape=self.filter_shape,\n",
    "            image_shape=self.image_shape)\n",
    "        pooled_out = downsample.max_pool_2d(\n",
    "            input=conv_out, ds=self.poolsize, ignore_border=True)\n",
    "        self.output = self.activation_fn(\n",
    "            pooled_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "        self.output_dropout = self.output #在卷积层是没有dropout的\n",
    "\n",
    "class FullyConnectedLayer(object):\n",
    "    #全连接层\n",
    "    def __init__(self, n_in, n_out, activation_fn=sigmoid, p_dropout=0.0):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.activation_fn = activation_fn\n",
    "        self.p_dropout = p_dropout\n",
    "        # 初始化权值和偏置\n",
    "        self.w = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(\n",
    "                    loc=0.0, scale=np.sqrt(1.0/n_out), size=(n_in, n_out)),\n",
    "                dtype=theano.config.floatX),\n",
    "            name='w', borrow=True)\n",
    "        self.b = theano.shared(\n",
    "            np.asarray(np.random.normal(loc=0.0, scale=1.0, size=(n_out,)),\n",
    "                       dtype=theano.config.floatX),\n",
    "            name='b', borrow=True)\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def set_inpt(self, inpt, inpt_dropout, mini_batch_size):\n",
    "        self.inpt = inpt.reshape((mini_batch_size, self.n_in))\n",
    "        self.output = self.activation_fn(\n",
    "            (1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b)\n",
    "        self.y_out = T.argmax(self.output, axis=1)\n",
    "        self.inpt_dropout = dropout_layer(\n",
    "            inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout)\n",
    "        self.output_dropout = self.activation_fn(\n",
    "            T.dot(self.inpt_dropout, self.w) + self.b)\n",
    "\n",
    "    def accuracy(self, y):\n",
    "        \"Return the accuracy for the mini-batch.\"\n",
    "        return T.mean(T.eq(y, self.y_out))\n",
    "\n",
    "class SoftmaxLayer(object):\n",
    "    #输出层\n",
    "    def __init__(self, n_in, n_out, p_dropout=0.0):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.p_dropout = p_dropout\n",
    "        # 初始化权值和偏置\n",
    "        self.w = theano.shared(\n",
    "            np.zeros((n_in, n_out), dtype=theano.config.floatX),\n",
    "            name='w', borrow=True)\n",
    "        self.b = theano.shared(\n",
    "            np.zeros((n_out,), dtype=theano.config.floatX),\n",
    "            name='b', borrow=True)\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def set_inpt(self, inpt, inpt_dropout, mini_batch_size):\n",
    "        self.inpt = inpt.reshape((mini_batch_size, self.n_in))\n",
    "        self.output = softmax((1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b)\n",
    "        self.y_out = T.argmax(self.output, axis=1)\n",
    "        self.inpt_dropout = dropout_layer(\n",
    "            inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout)\n",
    "        self.output_dropout = softmax(T.dot(self.inpt_dropout, self.w) + self.b)\n",
    "\n",
    "    def cost(self, net):\n",
    "        \"Return the log-likelihood cost.\"\n",
    "        return -T.mean(T.log(self.output_dropout)[T.arange(net.y.shape[0]), net.y])\n",
    "\n",
    "    def accuracy(self, y):\n",
    "        \"Return the accuracy for the mini-batch.\"\n",
    "        return T.mean(T.eq(y, self.y_out))\n",
    "\n",
    "\n",
    "def size(data):\n",
    "    \"Return the size of the dataset `data`.\"\n",
    "    return data[0].get_value(borrow=True).shape[0]\n",
    "#添加dropout\n",
    "def dropout_layer(layer, p_dropout):\n",
    "    srng = shared_randomstreams.RandomStreams(\n",
    "        np.random.RandomState(0).randint(999999))\n",
    "    mask = srng.binomial(n=1, p=1-p_dropout, size=layer.shape)\n",
    "    return layer*T.cast(mask, theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data =load_data_shared()\n",
    "mini_batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只有全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 92.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 91.86%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 94.70%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 93.97%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 95.72%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.18%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 96.42%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.78%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 96.76%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.29%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 96.93%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.66%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 97.00%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.91%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 97.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.14%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 97.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.31%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 97.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.43%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 97.27%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.44%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 97.35%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.46%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 97.41%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.54%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 97.41%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 97.44%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.64%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 97.43%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 97.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.62%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 97.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.68%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 97.51%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.69%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 97.53%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.75%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 97.51%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 97.54%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.77%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 97.53%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 97.56%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.75%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 97.55%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 97.56%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.79%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 97.56%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 97.56%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.81%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 97.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.82%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 97.59%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.82%\n",
      "Training mini-batch number 150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 97.58%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 97.59%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.83%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 97.59%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.84%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 97.59%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.82%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 97.61%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.81%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 97.63%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.80%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 97.63%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 97.66%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.79%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 97.65%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 97.65%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 97.66%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.83%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 97.65%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 97.65%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 97.67%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.87%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 97.67%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.88%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 97.67%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.89%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 97.65%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 97.65%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 97.65%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 97.64%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 97.64%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 97.63%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 97.62%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 97.62%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 97.62%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 97.64%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 97.64%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 97.64%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 97.66%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 97.66%\n",
      "Finished training network.\n",
      "Best validation accuracy of 97.67% obtained at iteration 229999\n",
      "Corresponding test accuracy of 97.89%\n"
     ]
    }
   ],
   "source": [
    "net = Network([\n",
    "        FullyConnectedLayer(n_in=784, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.1, \n",
    "            validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加一层卷积层和一层池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 93.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 92.82%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 96.07%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.57%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 97.08%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.66%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 97.60%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.32%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 97.87%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.60%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 97.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.72%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.08%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.96%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.11%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.06%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.21%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.16%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.32%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.25%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 98.35%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.33%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 98.38%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.34%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 98.44%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.47%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 98.46%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.55%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 98.48%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.58%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 98.48%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.63%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 98.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.68%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 98.54%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.70%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 98.56%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.67%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 98.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.67%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 98.65%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.70%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 98.65%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.69%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 98.65%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.69%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 98.66%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.68%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 98.68%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.70%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 98.69%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.69%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 98.70%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.67%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 98.70%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.67%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 98.71%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.68%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 98.75%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.67%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 98.75%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.70%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 98.75%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.71%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 98.75%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.71%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 98.77%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.72%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 98.78%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.72%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 98.79%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.73%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 98.78%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 98.78%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 98.77%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 98.76%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 98.76%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 98.76%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 98.77%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 98.76%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 98.76%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 98.76%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 98.77%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 98.77%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 98.77%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 98.77%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 98.77%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 98.78%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 98.78%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 98.78%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 98.78%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 98.77%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 98.77%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 98.77%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 98.77%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 98.79%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.75%\n",
      "Finished training network.\n",
      "Best validation accuracy of 98.79% obtained at iteration 299999\n",
      "Corresponding test accuracy of 98.75%\n"
     ]
    }
   ],
   "source": [
    "net1 = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        FullyConnectedLayer(n_in=20*12*12, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net1.SGD(training_data, 60, mini_batch_size, 0.1, \n",
    "            validation_data, test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加两层卷积层和池化层\n",
    "可以看到其实准确度上升不大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 92.68%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 92.49%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 96.89%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.51%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 97.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.29%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 98.05%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.81%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.20%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.07%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.29%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.21%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.35%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.30%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.42%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.38%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.44%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.48%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.48%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.50%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 98.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.52%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 98.55%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.62%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 98.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.75%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 98.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.77%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 98.57%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 98.62%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.77%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 98.64%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.79%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 98.65%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.78%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 98.69%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.80%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 98.66%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 98.68%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 98.70%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.83%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 98.73%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.81%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 98.74%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.82%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 98.77%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.84%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 98.78%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.88%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 98.78%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 98.79%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.89%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 98.82%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.90%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 98.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.89%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 98.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.88%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 98.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.88%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 98.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.89%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 98.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.89%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 98.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.89%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 98.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.90%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 98.85%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.92%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 98.85%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.92%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 98.87%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.93%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 98.89%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.95%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 98.88%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 98.88%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 98.89%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.95%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 98.89%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.96%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 98.90%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.97%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 98.89%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 98.89%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 98.90%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.95%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.96%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.96%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.96%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.96%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.97%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.97%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.97%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.97%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 98.90%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 98.90%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 98.90%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 98.90%\n",
      "Finished training network.\n",
      "Best validation accuracy of 98.91% obtained at iteration 279999\n",
      "Corresponding test accuracy of 98.97%\n"
     ]
    }
   ],
   "source": [
    "net2 = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net2.SGD(training_data, 60, mini_batch_size, 0.1, \n",
    "            validation_data, test_data)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用ReLu函数作为激活函数，准确率突破到了99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 97.48%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.33%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 98.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.15%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 98.36%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.05%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 98.57%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.33%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.32%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.26%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.44%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.60%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.42%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.76%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.59%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.62%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 98.42%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 98.77%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.77%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 98.77%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.80%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 98.62%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 98.85%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.76%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 98.94%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.81%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 98.88%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 98.82%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 98.91%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 98.88%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 98.83%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 98.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.95%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 98.99%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.93%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.03%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 99.00%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 99.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.99%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 99.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.99%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 99.01%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 99.01%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 99.01%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 99.01%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 99.01%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 99.01%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: validation accuracy 99.01%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 99.01%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 99.00%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 99.00%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 99.00%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 99.00%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 99.00%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 99.00%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 98.99%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 98.99%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 98.99%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 98.99%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 99.00%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 99.00%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 99.00%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 99.00%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 99.00%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 98.99%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 98.99%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 98.99%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 98.99%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 99.00%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 99.00%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 99.00%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 99.00%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 99.01%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 99.01%\n",
      "Finished training network.\n",
      "Best validation accuracy of 99.03% obtained at iteration 134999\n",
      "Corresponding test accuracy of 98.99%\n"
     ]
    }
   ],
   "source": [
    "net3 = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net3.SGD(training_data, 60, mini_batch_size, 0.03, \n",
    "            validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用数据增强技术进行对数据扩充到原来的5倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_training_data,validation_data, test_data= load_data_shared(filename=\"G:/data/mnist_expanded.pkl.gz\")\n",
    "mini_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 0: validation accuracy 98.88%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.14%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 1: validation accuracy 99.04%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.18%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 2: validation accuracy 99.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 3: validation accuracy 99.12%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 4: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.30%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 5: validation accuracy 99.08%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 6: validation accuracy 99.14%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 7: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.34%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 8: validation accuracy 99.20%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 9: validation accuracy 99.12%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 10: validation accuracy 99.16%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 11: validation accuracy 99.10%\n",
      "Training mini-batch number 300000\n",
      "Training mini-batch number 301000\n",
      "Training mini-batch number 302000\n",
      "Training mini-batch number 303000\n",
      "Training mini-batch number 304000\n",
      "Training mini-batch number 305000\n",
      "Training mini-batch number 306000\n",
      "Training mini-batch number 307000\n",
      "Training mini-batch number 308000\n",
      "Training mini-batch number 309000\n",
      "Training mini-batch number 310000\n",
      "Training mini-batch number 311000\n",
      "Training mini-batch number 312000\n",
      "Training mini-batch number 313000\n",
      "Training mini-batch number 314000\n",
      "Training mini-batch number 315000\n",
      "Training mini-batch number 316000\n",
      "Training mini-batch number 317000\n",
      "Training mini-batch number 318000\n",
      "Training mini-batch number 319000\n",
      "Training mini-batch number 320000\n",
      "Training mini-batch number 321000\n",
      "Training mini-batch number 322000\n",
      "Training mini-batch number 323000\n",
      "Training mini-batch number 324000\n",
      "Epoch 12: validation accuracy 99.33%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.19%\n",
      "Training mini-batch number 325000\n",
      "Training mini-batch number 326000\n",
      "Training mini-batch number 327000\n",
      "Training mini-batch number 328000\n",
      "Training mini-batch number 329000\n",
      "Training mini-batch number 330000\n",
      "Training mini-batch number 331000\n",
      "Training mini-batch number 332000\n",
      "Training mini-batch number 333000\n",
      "Training mini-batch number 334000\n",
      "Training mini-batch number 335000\n",
      "Training mini-batch number 336000\n",
      "Training mini-batch number 337000\n",
      "Training mini-batch number 338000\n",
      "Training mini-batch number 339000\n",
      "Training mini-batch number 340000\n",
      "Training mini-batch number 341000\n",
      "Training mini-batch number 342000\n",
      "Training mini-batch number 343000\n",
      "Training mini-batch number 344000\n",
      "Training mini-batch number 345000\n",
      "Training mini-batch number 346000\n",
      "Training mini-batch number 347000\n",
      "Training mini-batch number 348000\n",
      "Training mini-batch number 349000\n",
      "Epoch 13: validation accuracy 99.08%\n",
      "Training mini-batch number 350000\n",
      "Training mini-batch number 351000\n",
      "Training mini-batch number 352000\n",
      "Training mini-batch number 353000\n",
      "Training mini-batch number 354000\n",
      "Training mini-batch number 355000\n",
      "Training mini-batch number 356000\n",
      "Training mini-batch number 357000\n",
      "Training mini-batch number 358000\n",
      "Training mini-batch number 359000\n",
      "Training mini-batch number 360000\n",
      "Training mini-batch number 361000\n",
      "Training mini-batch number 362000\n",
      "Training mini-batch number 363000\n",
      "Training mini-batch number 364000\n",
      "Training mini-batch number 365000\n",
      "Training mini-batch number 366000\n",
      "Training mini-batch number 367000\n",
      "Training mini-batch number 368000\n",
      "Training mini-batch number 369000\n",
      "Training mini-batch number 370000\n",
      "Training mini-batch number 371000\n",
      "Training mini-batch number 372000\n",
      "Training mini-batch number 373000\n",
      "Training mini-batch number 374000\n",
      "Epoch 14: validation accuracy 99.10%\n",
      "Training mini-batch number 375000\n",
      "Training mini-batch number 376000\n",
      "Training mini-batch number 377000\n",
      "Training mini-batch number 378000\n",
      "Training mini-batch number 379000\n",
      "Training mini-batch number 380000\n",
      "Training mini-batch number 381000\n",
      "Training mini-batch number 382000\n",
      "Training mini-batch number 383000\n",
      "Training mini-batch number 384000\n",
      "Training mini-batch number 385000\n",
      "Training mini-batch number 386000\n",
      "Training mini-batch number 387000\n",
      "Training mini-batch number 388000\n",
      "Training mini-batch number 389000\n",
      "Training mini-batch number 390000\n",
      "Training mini-batch number 391000\n",
      "Training mini-batch number 392000\n",
      "Training mini-batch number 393000\n",
      "Training mini-batch number 394000\n",
      "Training mini-batch number 395000\n",
      "Training mini-batch number 396000\n",
      "Training mini-batch number 397000\n",
      "Training mini-batch number 398000\n",
      "Training mini-batch number 399000\n",
      "Epoch 15: validation accuracy 99.21%\n",
      "Training mini-batch number 400000\n",
      "Training mini-batch number 401000\n",
      "Training mini-batch number 402000\n",
      "Training mini-batch number 403000\n",
      "Training mini-batch number 404000\n",
      "Training mini-batch number 405000\n",
      "Training mini-batch number 406000\n",
      "Training mini-batch number 407000\n",
      "Training mini-batch number 408000\n",
      "Training mini-batch number 409000\n",
      "Training mini-batch number 410000\n",
      "Training mini-batch number 411000\n",
      "Training mini-batch number 412000\n",
      "Training mini-batch number 413000\n",
      "Training mini-batch number 414000\n",
      "Training mini-batch number 415000\n",
      "Training mini-batch number 416000\n",
      "Training mini-batch number 417000\n",
      "Training mini-batch number 418000\n",
      "Training mini-batch number 419000\n",
      "Training mini-batch number 420000\n",
      "Training mini-batch number 421000\n",
      "Training mini-batch number 422000\n",
      "Training mini-batch number 423000\n",
      "Training mini-batch number 424000\n",
      "Epoch 16: validation accuracy 99.15%\n",
      "Training mini-batch number 425000\n",
      "Training mini-batch number 426000\n",
      "Training mini-batch number 427000\n",
      "Training mini-batch number 428000\n",
      "Training mini-batch number 429000\n",
      "Training mini-batch number 430000\n",
      "Training mini-batch number 431000\n",
      "Training mini-batch number 432000\n",
      "Training mini-batch number 433000\n",
      "Training mini-batch number 434000\n",
      "Training mini-batch number 435000\n",
      "Training mini-batch number 436000\n",
      "Training mini-batch number 437000\n",
      "Training mini-batch number 438000\n",
      "Training mini-batch number 439000\n",
      "Training mini-batch number 440000\n",
      "Training mini-batch number 441000\n",
      "Training mini-batch number 442000\n",
      "Training mini-batch number 443000\n",
      "Training mini-batch number 444000\n",
      "Training mini-batch number 445000\n",
      "Training mini-batch number 446000\n",
      "Training mini-batch number 447000\n",
      "Training mini-batch number 448000\n",
      "Training mini-batch number 449000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: validation accuracy 99.16%\n",
      "Training mini-batch number 450000\n",
      "Training mini-batch number 451000\n",
      "Training mini-batch number 452000\n",
      "Training mini-batch number 453000\n",
      "Training mini-batch number 454000\n",
      "Training mini-batch number 455000\n",
      "Training mini-batch number 456000\n",
      "Training mini-batch number 457000\n",
      "Training mini-batch number 458000\n",
      "Training mini-batch number 459000\n",
      "Training mini-batch number 460000\n",
      "Training mini-batch number 461000\n",
      "Training mini-batch number 462000\n",
      "Training mini-batch number 463000\n",
      "Training mini-batch number 464000\n",
      "Training mini-batch number 465000\n",
      "Training mini-batch number 466000\n",
      "Training mini-batch number 467000\n",
      "Training mini-batch number 468000\n",
      "Training mini-batch number 469000\n",
      "Training mini-batch number 470000\n",
      "Training mini-batch number 471000\n",
      "Training mini-batch number 472000\n",
      "Training mini-batch number 473000\n",
      "Training mini-batch number 474000\n",
      "Epoch 18: validation accuracy 99.20%\n",
      "Training mini-batch number 475000\n",
      "Training mini-batch number 476000\n",
      "Training mini-batch number 477000\n",
      "Training mini-batch number 478000\n",
      "Training mini-batch number 479000\n",
      "Training mini-batch number 480000\n",
      "Training mini-batch number 481000\n",
      "Training mini-batch number 482000\n",
      "Training mini-batch number 483000\n",
      "Training mini-batch number 484000\n",
      "Training mini-batch number 485000\n",
      "Training mini-batch number 486000\n",
      "Training mini-batch number 487000\n",
      "Training mini-batch number 488000\n",
      "Training mini-batch number 489000\n",
      "Training mini-batch number 490000\n",
      "Training mini-batch number 491000\n",
      "Training mini-batch number 492000\n",
      "Training mini-batch number 493000\n",
      "Training mini-batch number 494000\n",
      "Training mini-batch number 495000\n",
      "Training mini-batch number 496000\n",
      "Training mini-batch number 497000\n",
      "Training mini-batch number 498000\n",
      "Training mini-batch number 499000\n",
      "Epoch 19: validation accuracy 99.15%\n",
      "Training mini-batch number 500000\n",
      "Training mini-batch number 501000\n",
      "Training mini-batch number 502000\n",
      "Training mini-batch number 503000\n",
      "Training mini-batch number 504000\n",
      "Training mini-batch number 505000\n",
      "Training mini-batch number 506000\n",
      "Training mini-batch number 507000\n",
      "Training mini-batch number 508000\n",
      "Training mini-batch number 509000\n",
      "Training mini-batch number 510000\n",
      "Training mini-batch number 511000\n",
      "Training mini-batch number 512000\n",
      "Training mini-batch number 513000\n",
      "Training mini-batch number 514000\n",
      "Training mini-batch number 515000\n",
      "Training mini-batch number 516000\n",
      "Training mini-batch number 517000\n",
      "Training mini-batch number 518000\n",
      "Training mini-batch number 519000\n",
      "Training mini-batch number 520000\n",
      "Training mini-batch number 521000\n",
      "Training mini-batch number 522000\n",
      "Training mini-batch number 523000\n",
      "Training mini-batch number 524000\n",
      "Epoch 20: validation accuracy 99.20%\n",
      "Training mini-batch number 525000\n",
      "Training mini-batch number 526000\n",
      "Training mini-batch number 527000\n",
      "Training mini-batch number 528000\n",
      "Training mini-batch number 529000\n",
      "Training mini-batch number 530000\n",
      "Training mini-batch number 531000\n",
      "Training mini-batch number 532000\n",
      "Training mini-batch number 533000\n",
      "Training mini-batch number 534000\n",
      "Training mini-batch number 535000\n",
      "Training mini-batch number 536000\n",
      "Training mini-batch number 537000\n",
      "Training mini-batch number 538000\n",
      "Training mini-batch number 539000\n",
      "Training mini-batch number 540000\n",
      "Training mini-batch number 541000\n",
      "Training mini-batch number 542000\n",
      "Training mini-batch number 543000\n",
      "Training mini-batch number 544000\n",
      "Training mini-batch number 545000\n",
      "Training mini-batch number 546000\n",
      "Training mini-batch number 547000\n",
      "Training mini-batch number 548000\n",
      "Training mini-batch number 549000\n",
      "Epoch 21: validation accuracy 99.22%\n",
      "Training mini-batch number 550000\n",
      "Training mini-batch number 551000\n",
      "Training mini-batch number 552000\n",
      "Training mini-batch number 553000\n",
      "Training mini-batch number 554000\n",
      "Training mini-batch number 555000\n",
      "Training mini-batch number 556000\n",
      "Training mini-batch number 557000\n",
      "Training mini-batch number 558000\n",
      "Training mini-batch number 559000\n",
      "Training mini-batch number 560000\n",
      "Training mini-batch number 561000\n",
      "Training mini-batch number 562000\n",
      "Training mini-batch number 563000\n",
      "Training mini-batch number 564000\n",
      "Training mini-batch number 565000\n",
      "Training mini-batch number 566000\n",
      "Training mini-batch number 567000\n",
      "Training mini-batch number 568000\n",
      "Training mini-batch number 569000\n",
      "Training mini-batch number 570000\n",
      "Training mini-batch number 571000\n",
      "Training mini-batch number 572000\n",
      "Training mini-batch number 573000\n",
      "Training mini-batch number 574000\n",
      "Epoch 22: validation accuracy 99.19%\n",
      "Training mini-batch number 575000\n",
      "Training mini-batch number 576000\n",
      "Training mini-batch number 577000\n",
      "Training mini-batch number 578000\n",
      "Training mini-batch number 579000\n",
      "Training mini-batch number 580000\n",
      "Training mini-batch number 581000\n",
      "Training mini-batch number 582000\n",
      "Training mini-batch number 583000\n",
      "Training mini-batch number 584000\n",
      "Training mini-batch number 585000\n",
      "Training mini-batch number 586000\n",
      "Training mini-batch number 587000\n",
      "Training mini-batch number 588000\n",
      "Training mini-batch number 589000\n",
      "Training mini-batch number 590000\n",
      "Training mini-batch number 591000\n",
      "Training mini-batch number 592000\n",
      "Training mini-batch number 593000\n",
      "Training mini-batch number 594000\n",
      "Training mini-batch number 595000\n",
      "Training mini-batch number 596000\n",
      "Training mini-batch number 597000\n",
      "Training mini-batch number 598000\n",
      "Training mini-batch number 599000\n",
      "Epoch 23: validation accuracy 99.33%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.30%\n",
      "Training mini-batch number 600000\n",
      "Training mini-batch number 601000\n",
      "Training mini-batch number 602000\n",
      "Training mini-batch number 603000\n",
      "Training mini-batch number 604000\n",
      "Training mini-batch number 605000\n",
      "Training mini-batch number 606000\n",
      "Training mini-batch number 607000\n",
      "Training mini-batch number 608000\n",
      "Training mini-batch number 609000\n",
      "Training mini-batch number 610000\n",
      "Training mini-batch number 611000\n",
      "Training mini-batch number 612000\n",
      "Training mini-batch number 613000\n",
      "Training mini-batch number 614000\n",
      "Training mini-batch number 615000\n",
      "Training mini-batch number 616000\n",
      "Training mini-batch number 617000\n",
      "Training mini-batch number 618000\n",
      "Training mini-batch number 619000\n",
      "Training mini-batch number 620000\n",
      "Training mini-batch number 621000\n",
      "Training mini-batch number 622000\n",
      "Training mini-batch number 623000\n",
      "Training mini-batch number 624000\n",
      "Epoch 24: validation accuracy 99.17%\n",
      "Training mini-batch number 625000\n",
      "Training mini-batch number 626000\n",
      "Training mini-batch number 627000\n",
      "Training mini-batch number 628000\n",
      "Training mini-batch number 629000\n",
      "Training mini-batch number 630000\n",
      "Training mini-batch number 631000\n",
      "Training mini-batch number 632000\n",
      "Training mini-batch number 633000\n",
      "Training mini-batch number 634000\n",
      "Training mini-batch number 635000\n",
      "Training mini-batch number 636000\n",
      "Training mini-batch number 637000\n",
      "Training mini-batch number 638000\n",
      "Training mini-batch number 639000\n",
      "Training mini-batch number 640000\n",
      "Training mini-batch number 641000\n",
      "Training mini-batch number 642000\n",
      "Training mini-batch number 643000\n",
      "Training mini-batch number 644000\n",
      "Training mini-batch number 645000\n",
      "Training mini-batch number 646000\n",
      "Training mini-batch number 647000\n",
      "Training mini-batch number 648000\n",
      "Training mini-batch number 649000\n",
      "Epoch 25: validation accuracy 99.20%\n",
      "Training mini-batch number 650000\n",
      "Training mini-batch number 651000\n",
      "Training mini-batch number 652000\n",
      "Training mini-batch number 653000\n",
      "Training mini-batch number 654000\n",
      "Training mini-batch number 655000\n",
      "Training mini-batch number 656000\n",
      "Training mini-batch number 657000\n",
      "Training mini-batch number 658000\n",
      "Training mini-batch number 659000\n",
      "Training mini-batch number 660000\n",
      "Training mini-batch number 661000\n",
      "Training mini-batch number 662000\n",
      "Training mini-batch number 663000\n",
      "Training mini-batch number 664000\n",
      "Training mini-batch number 665000\n",
      "Training mini-batch number 666000\n",
      "Training mini-batch number 667000\n",
      "Training mini-batch number 668000\n",
      "Training mini-batch number 669000\n",
      "Training mini-batch number 670000\n",
      "Training mini-batch number 671000\n",
      "Training mini-batch number 672000\n",
      "Training mini-batch number 673000\n",
      "Training mini-batch number 674000\n",
      "Epoch 26: validation accuracy 99.19%\n",
      "Training mini-batch number 675000\n",
      "Training mini-batch number 676000\n",
      "Training mini-batch number 677000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 678000\n",
      "Training mini-batch number 679000\n",
      "Training mini-batch number 680000\n",
      "Training mini-batch number 681000\n",
      "Training mini-batch number 682000\n",
      "Training mini-batch number 683000\n",
      "Training mini-batch number 684000\n",
      "Training mini-batch number 685000\n",
      "Training mini-batch number 686000\n",
      "Training mini-batch number 687000\n",
      "Training mini-batch number 688000\n",
      "Training mini-batch number 689000\n",
      "Training mini-batch number 690000\n",
      "Training mini-batch number 691000\n",
      "Training mini-batch number 692000\n",
      "Training mini-batch number 693000\n",
      "Training mini-batch number 694000\n",
      "Training mini-batch number 695000\n",
      "Training mini-batch number 696000\n",
      "Training mini-batch number 697000\n",
      "Training mini-batch number 698000\n",
      "Training mini-batch number 699000\n",
      "Epoch 27: validation accuracy 99.23%\n",
      "Training mini-batch number 700000\n",
      "Training mini-batch number 701000\n",
      "Training mini-batch number 702000\n",
      "Training mini-batch number 703000\n",
      "Training mini-batch number 704000\n",
      "Training mini-batch number 705000\n",
      "Training mini-batch number 706000\n",
      "Training mini-batch number 707000\n",
      "Training mini-batch number 708000\n",
      "Training mini-batch number 709000\n",
      "Training mini-batch number 710000\n",
      "Training mini-batch number 711000\n",
      "Training mini-batch number 712000\n",
      "Training mini-batch number 713000\n",
      "Training mini-batch number 714000\n",
      "Training mini-batch number 715000\n",
      "Training mini-batch number 716000\n",
      "Training mini-batch number 717000\n",
      "Training mini-batch number 718000\n",
      "Training mini-batch number 719000\n",
      "Training mini-batch number 720000\n",
      "Training mini-batch number 721000\n",
      "Training mini-batch number 722000\n",
      "Training mini-batch number 723000\n",
      "Training mini-batch number 724000\n",
      "Epoch 28: validation accuracy 99.30%\n",
      "Training mini-batch number 725000\n",
      "Training mini-batch number 726000\n",
      "Training mini-batch number 727000\n",
      "Training mini-batch number 728000\n",
      "Training mini-batch number 729000\n",
      "Training mini-batch number 730000\n",
      "Training mini-batch number 731000\n",
      "Training mini-batch number 732000\n",
      "Training mini-batch number 733000\n",
      "Training mini-batch number 734000\n",
      "Training mini-batch number 735000\n",
      "Training mini-batch number 736000\n",
      "Training mini-batch number 737000\n",
      "Training mini-batch number 738000\n",
      "Training mini-batch number 739000\n",
      "Training mini-batch number 740000\n",
      "Training mini-batch number 741000\n",
      "Training mini-batch number 742000\n",
      "Training mini-batch number 743000\n",
      "Training mini-batch number 744000\n",
      "Training mini-batch number 745000\n",
      "Training mini-batch number 746000\n",
      "Training mini-batch number 747000\n",
      "Training mini-batch number 748000\n",
      "Training mini-batch number 749000\n",
      "Epoch 29: validation accuracy 99.22%\n",
      "Training mini-batch number 750000\n",
      "Training mini-batch number 751000\n",
      "Training mini-batch number 752000\n",
      "Training mini-batch number 753000\n",
      "Training mini-batch number 754000\n",
      "Training mini-batch number 755000\n",
      "Training mini-batch number 756000\n",
      "Training mini-batch number 757000\n",
      "Training mini-batch number 758000\n",
      "Training mini-batch number 759000\n",
      "Training mini-batch number 760000\n",
      "Training mini-batch number 761000\n",
      "Training mini-batch number 762000\n",
      "Training mini-batch number 763000\n",
      "Training mini-batch number 764000\n",
      "Training mini-batch number 765000\n",
      "Training mini-batch number 766000\n",
      "Training mini-batch number 767000\n",
      "Training mini-batch number 768000\n",
      "Training mini-batch number 769000\n",
      "Training mini-batch number 770000\n",
      "Training mini-batch number 771000\n",
      "Training mini-batch number 772000\n",
      "Training mini-batch number 773000\n",
      "Training mini-batch number 774000\n",
      "Epoch 30: validation accuracy 99.29%\n",
      "Training mini-batch number 775000\n",
      "Training mini-batch number 776000\n",
      "Training mini-batch number 777000\n",
      "Training mini-batch number 778000\n",
      "Training mini-batch number 779000\n",
      "Training mini-batch number 780000\n",
      "Training mini-batch number 781000\n",
      "Training mini-batch number 782000\n",
      "Training mini-batch number 783000\n",
      "Training mini-batch number 784000\n",
      "Training mini-batch number 785000\n",
      "Training mini-batch number 786000\n",
      "Training mini-batch number 787000\n",
      "Training mini-batch number 788000\n",
      "Training mini-batch number 789000\n",
      "Training mini-batch number 790000\n",
      "Training mini-batch number 791000\n",
      "Training mini-batch number 792000\n",
      "Training mini-batch number 793000\n",
      "Training mini-batch number 794000\n",
      "Training mini-batch number 795000\n",
      "Training mini-batch number 796000\n",
      "Training mini-batch number 797000\n",
      "Training mini-batch number 798000\n",
      "Training mini-batch number 799000\n",
      "Epoch 31: validation accuracy 99.36%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.37%\n",
      "Training mini-batch number 800000\n",
      "Training mini-batch number 801000\n",
      "Training mini-batch number 802000\n",
      "Training mini-batch number 803000\n",
      "Training mini-batch number 804000\n",
      "Training mini-batch number 805000\n",
      "Training mini-batch number 806000\n",
      "Training mini-batch number 807000\n",
      "Training mini-batch number 808000\n",
      "Training mini-batch number 809000\n",
      "Training mini-batch number 810000\n",
      "Training mini-batch number 811000\n",
      "Training mini-batch number 812000\n",
      "Training mini-batch number 813000\n",
      "Training mini-batch number 814000\n",
      "Training mini-batch number 815000\n",
      "Training mini-batch number 816000\n",
      "Training mini-batch number 817000\n",
      "Training mini-batch number 818000\n",
      "Training mini-batch number 819000\n",
      "Training mini-batch number 820000\n",
      "Training mini-batch number 821000\n",
      "Training mini-batch number 822000\n",
      "Training mini-batch number 823000\n",
      "Training mini-batch number 824000\n",
      "Epoch 32: validation accuracy 99.41%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.40%\n",
      "Training mini-batch number 825000\n",
      "Training mini-batch number 826000\n",
      "Training mini-batch number 827000\n",
      "Training mini-batch number 828000\n",
      "Training mini-batch number 829000\n",
      "Training mini-batch number 830000\n",
      "Training mini-batch number 831000\n",
      "Training mini-batch number 832000\n",
      "Training mini-batch number 833000\n",
      "Training mini-batch number 834000\n",
      "Training mini-batch number 835000\n",
      "Training mini-batch number 836000\n",
      "Training mini-batch number 837000\n",
      "Training mini-batch number 838000\n",
      "Training mini-batch number 839000\n",
      "Training mini-batch number 840000\n",
      "Training mini-batch number 841000\n",
      "Training mini-batch number 842000\n",
      "Training mini-batch number 843000\n",
      "Training mini-batch number 844000\n",
      "Training mini-batch number 845000\n",
      "Training mini-batch number 846000\n",
      "Training mini-batch number 847000\n",
      "Training mini-batch number 848000\n",
      "Training mini-batch number 849000\n",
      "Epoch 33: validation accuracy 99.39%\n",
      "Training mini-batch number 850000\n",
      "Training mini-batch number 851000\n",
      "Training mini-batch number 852000\n",
      "Training mini-batch number 853000\n",
      "Training mini-batch number 854000\n",
      "Training mini-batch number 855000\n",
      "Training mini-batch number 856000\n",
      "Training mini-batch number 857000\n",
      "Training mini-batch number 858000\n",
      "Training mini-batch number 859000\n",
      "Training mini-batch number 860000\n",
      "Training mini-batch number 861000\n",
      "Training mini-batch number 862000\n",
      "Training mini-batch number 863000\n",
      "Training mini-batch number 864000\n",
      "Training mini-batch number 865000\n",
      "Training mini-batch number 866000\n",
      "Training mini-batch number 867000\n",
      "Training mini-batch number 868000\n",
      "Training mini-batch number 869000\n",
      "Training mini-batch number 870000\n",
      "Training mini-batch number 871000\n",
      "Training mini-batch number 872000\n",
      "Training mini-batch number 873000\n",
      "Training mini-batch number 874000\n",
      "Epoch 34: validation accuracy 99.27%\n",
      "Training mini-batch number 875000\n",
      "Training mini-batch number 876000\n",
      "Training mini-batch number 877000\n",
      "Training mini-batch number 878000\n",
      "Training mini-batch number 879000\n",
      "Training mini-batch number 880000\n",
      "Training mini-batch number 881000\n",
      "Training mini-batch number 882000\n",
      "Training mini-batch number 883000\n",
      "Training mini-batch number 884000\n",
      "Training mini-batch number 885000\n",
      "Training mini-batch number 886000\n",
      "Training mini-batch number 887000\n",
      "Training mini-batch number 888000\n",
      "Training mini-batch number 889000\n",
      "Training mini-batch number 890000\n",
      "Training mini-batch number 891000\n",
      "Training mini-batch number 892000\n",
      "Training mini-batch number 893000\n",
      "Training mini-batch number 894000\n",
      "Training mini-batch number 895000\n",
      "Training mini-batch number 896000\n",
      "Training mini-batch number 897000\n",
      "Training mini-batch number 898000\n",
      "Training mini-batch number 899000\n",
      "Epoch 35: validation accuracy 99.22%\n",
      "Training mini-batch number 900000\n",
      "Training mini-batch number 901000\n",
      "Training mini-batch number 902000\n",
      "Training mini-batch number 903000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 904000\n",
      "Training mini-batch number 905000\n",
      "Training mini-batch number 906000\n",
      "Training mini-batch number 907000\n",
      "Training mini-batch number 908000\n",
      "Training mini-batch number 909000\n",
      "Training mini-batch number 910000\n",
      "Training mini-batch number 911000\n",
      "Training mini-batch number 912000\n",
      "Training mini-batch number 913000\n",
      "Training mini-batch number 914000\n",
      "Training mini-batch number 915000\n",
      "Training mini-batch number 916000\n",
      "Training mini-batch number 917000\n",
      "Training mini-batch number 918000\n",
      "Training mini-batch number 919000\n",
      "Training mini-batch number 920000\n",
      "Training mini-batch number 921000\n",
      "Training mini-batch number 922000\n",
      "Training mini-batch number 923000\n",
      "Training mini-batch number 924000\n",
      "Epoch 36: validation accuracy 99.30%\n",
      "Training mini-batch number 925000\n",
      "Training mini-batch number 926000\n",
      "Training mini-batch number 927000\n",
      "Training mini-batch number 928000\n",
      "Training mini-batch number 929000\n",
      "Training mini-batch number 930000\n",
      "Training mini-batch number 931000\n",
      "Training mini-batch number 932000\n",
      "Training mini-batch number 933000\n",
      "Training mini-batch number 934000\n",
      "Training mini-batch number 935000\n",
      "Training mini-batch number 936000\n",
      "Training mini-batch number 937000\n",
      "Training mini-batch number 938000\n",
      "Training mini-batch number 939000\n",
      "Training mini-batch number 940000\n",
      "Training mini-batch number 941000\n",
      "Training mini-batch number 942000\n",
      "Training mini-batch number 943000\n",
      "Training mini-batch number 944000\n",
      "Training mini-batch number 945000\n",
      "Training mini-batch number 946000\n",
      "Training mini-batch number 947000\n",
      "Training mini-batch number 948000\n",
      "Training mini-batch number 949000\n",
      "Epoch 37: validation accuracy 99.34%\n",
      "Training mini-batch number 950000\n",
      "Training mini-batch number 951000\n",
      "Training mini-batch number 952000\n",
      "Training mini-batch number 953000\n",
      "Training mini-batch number 954000\n",
      "Training mini-batch number 955000\n",
      "Training mini-batch number 956000\n",
      "Training mini-batch number 957000\n",
      "Training mini-batch number 958000\n",
      "Training mini-batch number 959000\n",
      "Training mini-batch number 960000\n",
      "Training mini-batch number 961000\n",
      "Training mini-batch number 962000\n",
      "Training mini-batch number 963000\n",
      "Training mini-batch number 964000\n",
      "Training mini-batch number 965000\n",
      "Training mini-batch number 966000\n",
      "Training mini-batch number 967000\n",
      "Training mini-batch number 968000\n",
      "Training mini-batch number 969000\n",
      "Training mini-batch number 970000\n",
      "Training mini-batch number 971000\n",
      "Training mini-batch number 972000\n",
      "Training mini-batch number 973000\n",
      "Training mini-batch number 974000\n",
      "Epoch 38: validation accuracy 99.32%\n",
      "Training mini-batch number 975000\n",
      "Training mini-batch number 976000\n",
      "Training mini-batch number 977000\n",
      "Training mini-batch number 978000\n",
      "Training mini-batch number 979000\n",
      "Training mini-batch number 980000\n",
      "Training mini-batch number 981000\n",
      "Training mini-batch number 982000\n",
      "Training mini-batch number 983000\n",
      "Training mini-batch number 984000\n",
      "Training mini-batch number 985000\n",
      "Training mini-batch number 986000\n",
      "Training mini-batch number 987000\n",
      "Training mini-batch number 988000\n",
      "Training mini-batch number 989000\n",
      "Training mini-batch number 990000\n",
      "Training mini-batch number 991000\n",
      "Training mini-batch number 992000\n",
      "Training mini-batch number 993000\n",
      "Training mini-batch number 994000\n",
      "Training mini-batch number 995000\n",
      "Training mini-batch number 996000\n",
      "Training mini-batch number 997000\n",
      "Training mini-batch number 998000\n",
      "Training mini-batch number 999000\n",
      "Epoch 39: validation accuracy 99.36%\n",
      "Training mini-batch number 1000000\n",
      "Training mini-batch number 1001000\n",
      "Training mini-batch number 1002000\n",
      "Training mini-batch number 1003000\n",
      "Training mini-batch number 1004000\n",
      "Training mini-batch number 1005000\n",
      "Training mini-batch number 1006000\n",
      "Training mini-batch number 1007000\n",
      "Training mini-batch number 1008000\n",
      "Training mini-batch number 1009000\n",
      "Training mini-batch number 1010000\n",
      "Training mini-batch number 1011000\n",
      "Training mini-batch number 1012000\n",
      "Training mini-batch number 1013000\n",
      "Training mini-batch number 1014000\n",
      "Training mini-batch number 1015000\n",
      "Training mini-batch number 1016000\n",
      "Training mini-batch number 1017000\n",
      "Training mini-batch number 1018000\n",
      "Training mini-batch number 1019000\n",
      "Training mini-batch number 1020000\n",
      "Training mini-batch number 1021000\n",
      "Training mini-batch number 1022000\n",
      "Training mini-batch number 1023000\n",
      "Training mini-batch number 1024000\n",
      "Epoch 40: validation accuracy 99.40%\n",
      "Training mini-batch number 1025000\n",
      "Training mini-batch number 1026000\n",
      "Training mini-batch number 1027000\n",
      "Training mini-batch number 1028000\n",
      "Training mini-batch number 1029000\n",
      "Training mini-batch number 1030000\n",
      "Training mini-batch number 1031000\n",
      "Training mini-batch number 1032000\n",
      "Training mini-batch number 1033000\n",
      "Training mini-batch number 1034000\n",
      "Training mini-batch number 1035000\n",
      "Training mini-batch number 1036000\n",
      "Training mini-batch number 1037000\n",
      "Training mini-batch number 1038000\n",
      "Training mini-batch number 1039000\n",
      "Training mini-batch number 1040000\n",
      "Training mini-batch number 1041000\n",
      "Training mini-batch number 1042000\n",
      "Training mini-batch number 1043000\n",
      "Training mini-batch number 1044000\n",
      "Training mini-batch number 1045000\n",
      "Training mini-batch number 1046000\n",
      "Training mini-batch number 1047000\n",
      "Training mini-batch number 1048000\n",
      "Training mini-batch number 1049000\n",
      "Epoch 41: validation accuracy 99.40%\n",
      "Training mini-batch number 1050000\n",
      "Training mini-batch number 1051000\n",
      "Training mini-batch number 1052000\n",
      "Training mini-batch number 1053000\n",
      "Training mini-batch number 1054000\n",
      "Training mini-batch number 1055000\n",
      "Training mini-batch number 1056000\n",
      "Training mini-batch number 1057000\n",
      "Training mini-batch number 1058000\n",
      "Training mini-batch number 1059000\n",
      "Training mini-batch number 1060000\n",
      "Training mini-batch number 1061000\n",
      "Training mini-batch number 1062000\n",
      "Training mini-batch number 1063000\n",
      "Training mini-batch number 1064000\n",
      "Training mini-batch number 1065000\n",
      "Training mini-batch number 1066000\n",
      "Training mini-batch number 1067000\n",
      "Training mini-batch number 1068000\n",
      "Training mini-batch number 1069000\n",
      "Training mini-batch number 1070000\n",
      "Training mini-batch number 1071000\n",
      "Training mini-batch number 1072000\n",
      "Training mini-batch number 1073000\n",
      "Training mini-batch number 1074000\n",
      "Epoch 42: validation accuracy 99.40%\n",
      "Training mini-batch number 1075000\n",
      "Training mini-batch number 1076000\n",
      "Training mini-batch number 1077000\n",
      "Training mini-batch number 1078000\n",
      "Training mini-batch number 1079000\n",
      "Training mini-batch number 1080000\n",
      "Training mini-batch number 1081000\n",
      "Training mini-batch number 1082000\n",
      "Training mini-batch number 1083000\n",
      "Training mini-batch number 1084000\n",
      "Training mini-batch number 1085000\n",
      "Training mini-batch number 1086000\n",
      "Training mini-batch number 1087000\n",
      "Training mini-batch number 1088000\n",
      "Training mini-batch number 1089000\n",
      "Training mini-batch number 1090000\n",
      "Training mini-batch number 1091000\n",
      "Training mini-batch number 1092000\n",
      "Training mini-batch number 1093000\n",
      "Training mini-batch number 1094000\n",
      "Training mini-batch number 1095000\n",
      "Training mini-batch number 1096000\n",
      "Training mini-batch number 1097000\n",
      "Training mini-batch number 1098000\n",
      "Training mini-batch number 1099000\n",
      "Epoch 43: validation accuracy 99.41%\n",
      "Training mini-batch number 1100000\n",
      "Training mini-batch number 1101000\n",
      "Training mini-batch number 1102000\n",
      "Training mini-batch number 1103000\n",
      "Training mini-batch number 1104000\n",
      "Training mini-batch number 1105000\n",
      "Training mini-batch number 1106000\n",
      "Training mini-batch number 1107000\n",
      "Training mini-batch number 1108000\n",
      "Training mini-batch number 1109000\n",
      "Training mini-batch number 1110000\n",
      "Training mini-batch number 1111000\n",
      "Training mini-batch number 1112000\n",
      "Training mini-batch number 1113000\n",
      "Training mini-batch number 1114000\n",
      "Training mini-batch number 1115000\n",
      "Training mini-batch number 1116000\n",
      "Training mini-batch number 1117000\n",
      "Training mini-batch number 1118000\n",
      "Training mini-batch number 1119000\n",
      "Training mini-batch number 1120000\n",
      "Training mini-batch number 1121000\n",
      "Training mini-batch number 1122000\n",
      "Training mini-batch number 1123000\n",
      "Training mini-batch number 1124000\n",
      "Epoch 44: validation accuracy 99.41%\n",
      "Training mini-batch number 1125000\n",
      "Training mini-batch number 1126000\n",
      "Training mini-batch number 1127000\n",
      "Training mini-batch number 1128000\n",
      "Training mini-batch number 1129000\n",
      "Training mini-batch number 1130000\n",
      "Training mini-batch number 1131000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 1132000\n",
      "Training mini-batch number 1133000\n",
      "Training mini-batch number 1134000\n",
      "Training mini-batch number 1135000\n",
      "Training mini-batch number 1136000\n",
      "Training mini-batch number 1137000\n",
      "Training mini-batch number 1138000\n",
      "Training mini-batch number 1139000\n",
      "Training mini-batch number 1140000\n",
      "Training mini-batch number 1141000\n",
      "Training mini-batch number 1142000\n",
      "Training mini-batch number 1143000\n",
      "Training mini-batch number 1144000\n",
      "Training mini-batch number 1145000\n",
      "Training mini-batch number 1146000\n",
      "Training mini-batch number 1147000\n",
      "Training mini-batch number 1148000\n",
      "Training mini-batch number 1149000\n",
      "Epoch 45: validation accuracy 99.42%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.47%\n",
      "Training mini-batch number 1150000\n",
      "Training mini-batch number 1151000\n",
      "Training mini-batch number 1152000\n",
      "Training mini-batch number 1153000\n",
      "Training mini-batch number 1154000\n",
      "Training mini-batch number 1155000\n",
      "Training mini-batch number 1156000\n",
      "Training mini-batch number 1157000\n",
      "Training mini-batch number 1158000\n",
      "Training mini-batch number 1159000\n",
      "Training mini-batch number 1160000\n",
      "Training mini-batch number 1161000\n",
      "Training mini-batch number 1162000\n",
      "Training mini-batch number 1163000\n",
      "Training mini-batch number 1164000\n",
      "Training mini-batch number 1165000\n",
      "Training mini-batch number 1166000\n",
      "Training mini-batch number 1167000\n",
      "Training mini-batch number 1168000\n",
      "Training mini-batch number 1169000\n",
      "Training mini-batch number 1170000\n",
      "Training mini-batch number 1171000\n",
      "Training mini-batch number 1172000\n",
      "Training mini-batch number 1173000\n",
      "Training mini-batch number 1174000\n",
      "Epoch 46: validation accuracy 99.42%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.47%\n",
      "Training mini-batch number 1175000\n",
      "Training mini-batch number 1176000\n",
      "Training mini-batch number 1177000\n",
      "Training mini-batch number 1178000\n",
      "Training mini-batch number 1179000\n",
      "Training mini-batch number 1180000\n",
      "Training mini-batch number 1181000\n",
      "Training mini-batch number 1182000\n",
      "Training mini-batch number 1183000\n",
      "Training mini-batch number 1184000\n",
      "Training mini-batch number 1185000\n",
      "Training mini-batch number 1186000\n",
      "Training mini-batch number 1187000\n",
      "Training mini-batch number 1188000\n",
      "Training mini-batch number 1189000\n",
      "Training mini-batch number 1190000\n",
      "Training mini-batch number 1191000\n",
      "Training mini-batch number 1192000\n",
      "Training mini-batch number 1193000\n",
      "Training mini-batch number 1194000\n",
      "Training mini-batch number 1195000\n",
      "Training mini-batch number 1196000\n",
      "Training mini-batch number 1197000\n",
      "Training mini-batch number 1198000\n",
      "Training mini-batch number 1199000\n",
      "Epoch 47: validation accuracy 99.42%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.47%\n",
      "Training mini-batch number 1200000\n",
      "Training mini-batch number 1201000\n",
      "Training mini-batch number 1202000\n",
      "Training mini-batch number 1203000\n",
      "Training mini-batch number 1204000\n",
      "Training mini-batch number 1205000\n",
      "Training mini-batch number 1206000\n",
      "Training mini-batch number 1207000\n",
      "Training mini-batch number 1208000\n",
      "Training mini-batch number 1209000\n",
      "Training mini-batch number 1210000\n",
      "Training mini-batch number 1211000\n",
      "Training mini-batch number 1212000\n",
      "Training mini-batch number 1213000\n",
      "Training mini-batch number 1214000\n",
      "Training mini-batch number 1215000\n",
      "Training mini-batch number 1216000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6e86a85b1e57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n\u001b[0;32m     12\u001b[0m net4.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n\u001b[1;32m---> 13\u001b[1;33m             validation_data, test_data, lmbda=0.1)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-a14542223964>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda)\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training mini-batch number {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[0mcost_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum_training_batches\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                     validation_accuracy = np.mean(\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoContext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net4 = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net4.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n",
    "            validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 经过观察到了epoch45以后交叉验证集没有明显变化，所以终止了代码运行\n",
    " \n",
    " 添加两层全连接层的情况\n",
    " net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=100, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n",
    "            validation_data, test_data, lmbda=0.1)\n",
    "\n",
    "添加两层全连接层，并对全连接层使用dropout=0.5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 0: validation accuracy 98.67%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.68%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 1: validation accuracy 99.08%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.15%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 2: validation accuracy 99.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.31%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 3: validation accuracy 99.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.43%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 4: validation accuracy 99.25%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.48%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 5: validation accuracy 99.27%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.38%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 6: validation accuracy 99.38%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.51%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 7: validation accuracy 99.39%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.51%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Training mini-batch number 215000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 8: validation accuracy 99.43%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.55%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 9: validation accuracy 99.40%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 10: validation accuracy 99.47%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.58%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 11: validation accuracy 99.47%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.57%\n",
      "Training mini-batch number 300000\n",
      "Training mini-batch number 301000\n",
      "Training mini-batch number 302000\n",
      "Training mini-batch number 303000\n",
      "Training mini-batch number 304000\n",
      "Training mini-batch number 305000\n",
      "Training mini-batch number 306000\n",
      "Training mini-batch number 307000\n",
      "Training mini-batch number 308000\n",
      "Training mini-batch number 309000\n",
      "Training mini-batch number 310000\n",
      "Training mini-batch number 311000\n",
      "Training mini-batch number 312000\n",
      "Training mini-batch number 313000\n",
      "Training mini-batch number 314000\n",
      "Training mini-batch number 315000\n",
      "Training mini-batch number 316000\n",
      "Training mini-batch number 317000\n",
      "Training mini-batch number 318000\n",
      "Training mini-batch number 319000\n",
      "Training mini-batch number 320000\n",
      "Training mini-batch number 321000\n",
      "Training mini-batch number 322000\n",
      "Training mini-batch number 323000\n",
      "Training mini-batch number 324000\n",
      "Epoch 12: validation accuracy 99.47%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.52%\n",
      "Training mini-batch number 325000\n",
      "Training mini-batch number 326000\n",
      "Training mini-batch number 327000\n",
      "Training mini-batch number 328000\n",
      "Training mini-batch number 329000\n",
      "Training mini-batch number 330000\n",
      "Training mini-batch number 331000\n",
      "Training mini-batch number 332000\n",
      "Training mini-batch number 333000\n",
      "Training mini-batch number 334000\n",
      "Training mini-batch number 335000\n",
      "Training mini-batch number 336000\n",
      "Training mini-batch number 337000\n",
      "Training mini-batch number 338000\n",
      "Training mini-batch number 339000\n",
      "Training mini-batch number 340000\n",
      "Training mini-batch number 341000\n",
      "Training mini-batch number 342000\n",
      "Training mini-batch number 343000\n",
      "Training mini-batch number 344000\n",
      "Training mini-batch number 345000\n",
      "Training mini-batch number 346000\n",
      "Training mini-batch number 347000\n",
      "Training mini-batch number 348000\n",
      "Training mini-batch number 349000\n",
      "Epoch 13: validation accuracy 99.42%\n",
      "Training mini-batch number 350000\n",
      "Training mini-batch number 351000\n",
      "Training mini-batch number 352000\n",
      "Training mini-batch number 353000\n",
      "Training mini-batch number 354000\n",
      "Training mini-batch number 355000\n",
      "Training mini-batch number 356000\n",
      "Training mini-batch number 357000\n",
      "Training mini-batch number 358000\n",
      "Training mini-batch number 359000\n",
      "Training mini-batch number 360000\n",
      "Training mini-batch number 361000\n",
      "Training mini-batch number 362000\n",
      "Training mini-batch number 363000\n",
      "Training mini-batch number 364000\n",
      "Training mini-batch number 365000\n",
      "Training mini-batch number 366000\n",
      "Training mini-batch number 367000\n",
      "Training mini-batch number 368000\n",
      "Training mini-batch number 369000\n",
      "Training mini-batch number 370000\n",
      "Training mini-batch number 371000\n",
      "Training mini-batch number 372000\n",
      "Training mini-batch number 373000\n",
      "Training mini-batch number 374000\n",
      "Epoch 14: validation accuracy 99.52%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.56%\n",
      "Training mini-batch number 375000\n",
      "Training mini-batch number 376000\n",
      "Training mini-batch number 377000\n",
      "Training mini-batch number 378000\n",
      "Training mini-batch number 379000\n",
      "Training mini-batch number 380000\n",
      "Training mini-batch number 381000\n",
      "Training mini-batch number 382000\n",
      "Training mini-batch number 383000\n",
      "Training mini-batch number 384000\n",
      "Training mini-batch number 385000\n",
      "Training mini-batch number 386000\n",
      "Training mini-batch number 387000\n",
      "Training mini-batch number 388000\n",
      "Training mini-batch number 389000\n",
      "Training mini-batch number 390000\n",
      "Training mini-batch number 391000\n",
      "Training mini-batch number 392000\n",
      "Training mini-batch number 393000\n",
      "Training mini-batch number 394000\n",
      "Training mini-batch number 395000\n",
      "Training mini-batch number 396000\n",
      "Training mini-batch number 397000\n",
      "Training mini-batch number 398000\n",
      "Training mini-batch number 399000\n",
      "Epoch 15: validation accuracy 99.45%\n",
      "Training mini-batch number 400000\n",
      "Training mini-batch number 401000\n",
      "Training mini-batch number 402000\n",
      "Training mini-batch number 403000\n",
      "Training mini-batch number 404000\n",
      "Training mini-batch number 405000\n",
      "Training mini-batch number 406000\n",
      "Training mini-batch number 407000\n",
      "Training mini-batch number 408000\n",
      "Training mini-batch number 409000\n",
      "Training mini-batch number 410000\n",
      "Training mini-batch number 411000\n",
      "Training mini-batch number 412000\n",
      "Training mini-batch number 413000\n",
      "Training mini-batch number 414000\n",
      "Training mini-batch number 415000\n",
      "Training mini-batch number 416000\n",
      "Training mini-batch number 417000\n",
      "Training mini-batch number 418000\n",
      "Training mini-batch number 419000\n",
      "Training mini-batch number 420000\n",
      "Training mini-batch number 421000\n",
      "Training mini-batch number 422000\n",
      "Training mini-batch number 423000\n",
      "Training mini-batch number 424000\n",
      "Epoch 16: validation accuracy 99.42%\n",
      "Training mini-batch number 425000\n",
      "Training mini-batch number 426000\n",
      "Training mini-batch number 427000\n",
      "Training mini-batch number 428000\n",
      "Training mini-batch number 429000\n",
      "Training mini-batch number 430000\n",
      "Training mini-batch number 431000\n",
      "Training mini-batch number 432000\n",
      "Training mini-batch number 433000\n",
      "Training mini-batch number 434000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 435000\n",
      "Training mini-batch number 436000\n",
      "Training mini-batch number 437000\n",
      "Training mini-batch number 438000\n",
      "Training mini-batch number 439000\n",
      "Training mini-batch number 440000\n",
      "Training mini-batch number 441000\n",
      "Training mini-batch number 442000\n",
      "Training mini-batch number 443000\n",
      "Training mini-batch number 444000\n",
      "Training mini-batch number 445000\n",
      "Training mini-batch number 446000\n",
      "Training mini-batch number 447000\n",
      "Training mini-batch number 448000\n",
      "Training mini-batch number 449000\n",
      "Epoch 17: validation accuracy 99.46%\n",
      "Training mini-batch number 450000\n",
      "Training mini-batch number 451000\n",
      "Training mini-batch number 452000\n",
      "Training mini-batch number 453000\n",
      "Training mini-batch number 454000\n",
      "Training mini-batch number 455000\n",
      "Training mini-batch number 456000\n",
      "Training mini-batch number 457000\n",
      "Training mini-batch number 458000\n",
      "Training mini-batch number 459000\n",
      "Training mini-batch number 460000\n",
      "Training mini-batch number 461000\n",
      "Training mini-batch number 462000\n",
      "Training mini-batch number 463000\n",
      "Training mini-batch number 464000\n",
      "Training mini-batch number 465000\n",
      "Training mini-batch number 466000\n",
      "Training mini-batch number 467000\n",
      "Training mini-batch number 468000\n",
      "Training mini-batch number 469000\n",
      "Training mini-batch number 470000\n",
      "Training mini-batch number 471000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-33bf03218307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         mini_batch_size)\n\u001b[0;32m     18\u001b[0m net5.SGD(expanded_training_data, 40, mini_batch_size, 0.03, \n\u001b[1;32m---> 19\u001b[1;33m             validation_data, test_data)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-b390b7a79d0b>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda)\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training mini-batch number {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[0mcost_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[1;31m#每训练完一个epoch输出一次交叉验证集的准确度\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum_training_batches\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\theano\\tensor\\raw_random.py\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inputs, out_)\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mrout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                \u001b[1;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net5 = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(\n",
    "            n_in=40*4*4, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n",
    "        FullyConnectedLayer(\n",
    "            n_in=1000, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n",
    "        SoftmaxLayer(n_in=1000, n_out=10, p_dropout=0.5)], \n",
    "        mini_batch_size)\n",
    "net5.SGD(expanded_training_data,40, mini_batch_size, 0.03, \n",
    "            validation_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
